{
  "convnext_tiny": {
    "model_name": "convnext_tiny",
    "model_type": "cnn",
    "accuracy": 0.9813953488372092,
    "precision_weighted": 0.9824622744488225,
    "recall_weighted": 0.9813953488372092,
    "f1_weighted": 0.9815712331444205,
    "top5_accuracy": null,
    "total_params": 27824742,
    "trainable_params": 27824742,
    "model_size_mb": 106.1429672241211,
    "inference_time_ms": 3.67593001035857,
    "gpu_memory_mb": 0.0,
    "train_time_minutes": 19.74567366838455,
    "epochs_trained": 20,
    "best_epoch": 0,
    "per_class_metrics": {
      "cordana": {
        "precision": 1.0,
        "recall": 0.96875,
        "f1-score": 0.9841269841269841,
        "support": 32.0
      },
      "fusarium_r4t": {
        "precision": 1.0,
        "recall": 1.0,
        "f1-score": 1.0,
        "support": 2.0
      },
      "healthy": {
        "precision": 1.0,
        "recall": 0.9615384615384616,
        "f1-score": 0.9803921568627451,
        "support": 26.0
      },
      "moko": {
        "precision": 0.8947368421052632,
        "recall": 1.0,
        "f1-score": 0.9444444444444444,
        "support": 17.0
      },
      "pestalotiopsis": {
        "precision": 0.9714285714285714,
        "recall": 1.0,
        "f1-score": 0.9855072463768116,
        "support": 34.0
      },
      "sigatoka": {
        "precision": 0.9902912621359223,
        "recall": 0.9807692307692307,
        "f1-score": 0.9855072463768116,
        "support": 104.0
      },
      "accuracy": 0.9813953488372092,
      "macro avg": {
        "precision": 0.9760761126116261,
        "recall": 0.985176282051282,
        "f1-score": 0.9799963463646328,
        "support": 215.0
      },
      "weighted avg": {
        "precision": 0.9824622744488225,
        "recall": 0.9813953488372092,
        "f1-score": 0.9815712331444205,
        "support": 215.0
      }
    }
  }
}